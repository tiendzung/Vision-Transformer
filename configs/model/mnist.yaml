_target_: src.models.mnist_module.MNISTLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.0003
  weight_decay: 0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

# scheduler:
#   _target_: torch.optim.lr_scheduler.MultiStepLR ##torch.optim.lr_scheduler.ReduceLROnPlateau
#   _partial_: true
#   gamma: 0.1
#   milestones: [100, 150]



net:
  _target_: src.models.components.vision_transformer.VisionTransformer
  embed_dim: 256
  hidden_dim: 512
  num_channels: 1
  num_heads: 8
  num_layers: 16
  num_classes: 10
  patch_size: 4
  num_patches: 49
  device: ${trainer.accelerator}
  dropout : 0.2

# compile model for faster training with pytorch 2.0
compile: false
